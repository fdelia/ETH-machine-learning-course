{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "X = np.load('data/X_train.npy')#[0:load_n]\n",
    "y = np.genfromtxt('data/y_1.csv', delimiter='\\n')#[0:load_n]\n",
    "#data_test = np.load('data/X_test.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "class ClusteredHistExtraction(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=10, n_samples=2, images_x_from=False, images_x_to=False):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_samples = n_samples\n",
    "        self.images_x_from = images_x_from\n",
    "        self.images_x_to = images_x_to\n",
    "\n",
    "\n",
    "    def cutImage(self, x):\n",
    "        if self.images_x_from is not False and self.images_x_to is not False:\n",
    "            #images = np.split(row, 176)[50:130] # pretty optimal already\n",
    "            side_images = np.split(x, 176)[self.images_x_from : self.images_x_to]\n",
    "            x = np.array(side_images).flatten()\n",
    "        return x\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        samples = random.sample(list(X), self.n_samples)\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, n_jobs=-1, random_state=42)\n",
    "        # self.kmeans = MiniBatchKMeans(n_clusters=self.n_clusters, batch_size=100, random_state=42)\n",
    "\n",
    "        centers = []\n",
    "        for i, sample in enumerate(samples):\n",
    "            # samples[i] = sample[1672390 : -786303]\n",
    "            sample = self.cutImage(sample)\n",
    "\n",
    "            samples[i] = sample[(sample > 0) & (sample < 1800)]\n",
    "            self.kmeans.fit(np.array([samples[i]]).T)\n",
    "            centers.append(np.sort(np.array(self.kmeans.cluster_centers_).flatten()))\n",
    "            print(str(i) + ' done')\n",
    "\n",
    "        if True: # use all centers\n",
    "            values = np.array(centers).flatten()\n",
    "            values = np.sort(values)\n",
    "        else: # take means of centers\n",
    "            values = np.mean(centers, axis=0)\n",
    "\n",
    "\n",
    "        # compute cluster centers\n",
    "        #self.kmeans.fit(np.array(samples).T)\n",
    "        #values = self.kmeans.cluster_centers_.T\n",
    "        #print('fitted')\n",
    "\n",
    "        # mean of the clusters over the rows\n",
    "        #for i, v in enumerate(values.T):\n",
    "        #    values.T[i] = np.sort(v)\n",
    "\n",
    "        #values = np.mean(values.T, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        self.edges = [1] # leave out 0\n",
    "        for center_1, center_2 in zip(values[:-1], values[1:]):\n",
    "            self.edges.append(.5 * (center_1 + center_2))\n",
    "\n",
    "        print('n edges: ' + str(len(self.edges)))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # np.histogram to make bins from edges, counts the number of pixels\n",
    "        X_new = []\n",
    "        for x in X:\n",
    "            x = self.cutImage(x)\n",
    "            hist = np.histogram(x, bins=self.edges)\n",
    "            X_new.append(hist[0])\n",
    "\n",
    "        return X_new\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ClusteredHistExtraction', ClusteredHistExtraction(n_clusters=10,n_samples=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('vct', VarianceThreshold()),\n",
    "    ('kernelRidge', KernelRidge(kernel='polynomial'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    \n",
    "}\n",
    "grid = GridSearchCV(pipe, parameters, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "print(np.mean(grid.cv_results_['mean_test_score']))\n",
    "print(np.mean(grid.cv_results_[\"std_test_score\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
