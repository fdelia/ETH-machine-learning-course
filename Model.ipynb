{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "X = np.load('data/X_train.npy')#[0:load_n]\n",
    "y = np.genfromtxt('data/y_1.csv', delimiter='\\n')#[0:load_n]\n",
    "#data_test = np.load('data/X_test.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import random\n",
    "random.seed(99)\n",
    "\n",
    "class GivenBinHistExtraction(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_new = []\n",
    "        X_new = X\n",
    "        return X_new\n",
    "\n",
    "class ClusteredHistExtraction(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=10, n_samples=3, images_x_from=False, images_x_to=False):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_samples = n_samples\n",
    "        self.images_x_from = images_x_from\n",
    "        self.images_x_to = images_x_to\n",
    "\n",
    "\n",
    "    def cutImage(self, x):\n",
    "        if self.images_x_from is not False and self.images_x_to is not False:\n",
    "            #images = np.split(row, 176)[50:130] # pretty optimal already\n",
    "            side_images = np.split(x, 176)[self.images_x_from : self.images_x_to]\n",
    "            x = np.array(side_images).flatten()\n",
    "        return x\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        samples = random.sample(list(X), self.n_samples)\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, n_jobs=-1, random_state=42)\n",
    "        # self.kmeans = MiniBatchKMeans(n_clusters=self.n_clusters, batch_size=100, random_state=42)\n",
    "\n",
    "        centers = []\n",
    "        for i, sample in enumerate(samples):\n",
    "            # sample = sample[1672390 : -786303]\n",
    "            sample = self.cutImage(sample)\n",
    "\n",
    "            sample = sample[(sample > 0) & (sample < 1800)]\n",
    "            self.kmeans.fit(np.array([sample]).T)\n",
    "            centers.append(np.sort(np.array(self.kmeans.cluster_centers_).flatten()))\n",
    "            \n",
    "            samples[i] = sample\n",
    "            print(str(i) + ' done')\n",
    "\n",
    "        if True: # use all centers\n",
    "            values = np.array(centers).flatten()\n",
    "            values = np.sort(values)\n",
    "        else: # take means of centers\n",
    "            values = np.mean(centers, axis=0)\n",
    "\n",
    "        # compute cluster centers\n",
    "        #self.kmeans.fit(np.array(samples).T)\n",
    "        #values = self.kmeans.cluster_centers_.T\n",
    "        #print('fitted')\n",
    "\n",
    "        # mean of the clusters over the rows\n",
    "        #for i, v in enumerate(values.T):\n",
    "        #    values.T[i] = np.sort(v)\n",
    "\n",
    "        #values = np.mean(values.T, axis=0)\n",
    "\n",
    "        self.edges = [1] # leave out 0\n",
    "        for center_1, center_2 in zip(values[:-1], values[1:]):\n",
    "            self.edges.append(.5 * (center_1 + center_2))\n",
    "\n",
    "        print('n edges: ' + str(len(self.edges)))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # np.histogram to make bins from edges, counts the number of pixels\n",
    "        X_new = []\n",
    "        for x in X:\n",
    "            x = self.cutImage(x)\n",
    "            x = x[(x > 0) & (x < 1800)]\n",
    "            hist = np.histogram(x, bins=self.edges)\n",
    "            X_new.append(hist[0])\n",
    "\n",
    "        return X_new\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ClusteredHistExtraction', ClusteredHistExtraction(\n",
    "        n_clusters=10,n_samples=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('vct', VarianceThreshold()),\n",
    "    ('kernelRidge', KernelRidge(kernel='polynomial'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "0 done\n",
      "0 done\n",
      "0 done\n",
      "1 done\n",
      "1 done\n",
      "1 done\n",
      "1 done\n",
      "2 done\n",
      "n edges: 24\n",
      "2 done\n",
      "n edges: 24\n",
      "2 done\n",
      "n edges: 24\n",
      "2 done\n",
      "3 done\n",
      "n edges: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "0 done\n",
      "0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 done\n",
      "1 done\n",
      "1 done\n",
      "2 done\n",
      "0 done\n",
      "2 done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'ClusteredHistExtraction__n_clusters': [8, 10],\n",
    "    'ClusteredHistExtraction__n_samples': [3, 4]\n",
    "}\n",
    "grid = GridSearchCV(pipe, parameters, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "print(str(np.mean(grid.cv_results_['mean_test_score'])) + ', ' + str(np.mean(grid.cv_results_['std_test_score'])))\n",
    "\n",
    "# -68.8529277579 5.72349220142\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 434.77036532]),\n",
       " 'mean_score_time': array([ 13.97584867]),\n",
       " 'mean_test_score': array([-68.85292776]),\n",
       " 'mean_train_score': array([-36.90615834]),\n",
       " 'params': [{}],\n",
       " 'rank_test_score': array([1], dtype=int32),\n",
       " 'split0_test_score': array([-66.079159]),\n",
       " 'split0_train_score': array([-41.20961474]),\n",
       " 'split1_test_score': array([-76.80072573]),\n",
       " 'split1_train_score': array([-33.15582205]),\n",
       " 'split2_test_score': array([-63.6226591]),\n",
       " 'split2_train_score': array([-36.35303823]),\n",
       " 'std_fit_time': array([ 7.31600625]),\n",
       " 'std_score_time': array([ 0.25846821]),\n",
       " 'std_test_score': array([ 5.7234922]),\n",
       " 'std_train_score': array([ 3.31112776])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Search bin subdivision so that there is highest variance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
