{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "X = np.load('data/X_train.npy')\n",
    "y = np.genfromtxt('data/y_1.csv', delimiter='\\n')\n",
    "#data_test = np.load('data/X_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import random\n",
    "random.seed(99)\n",
    "\n",
    "class RandomBinsExtraction(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Build n bins with mean from values\"\"\"\n",
    "    def __init__(self, bin_length=3, splits=1000, hist_bins=None,\n",
    "        images_x_from=False, images_x_to=False,\n",
    "        images_y_from=False, images_y_to=False):\n",
    "        #self.bin_length = bin_length\n",
    "        self.splits = splits\n",
    "        self.hist_bins = hist_bins\n",
    "\n",
    "        self.images_x_from = images_x_from\n",
    "        self.images_x_to = images_x_to\n",
    "        self.images_y_from = 0 #images_y_from\n",
    "        self.images_y_to = 204 #images_y_to\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_new = []\n",
    "        split_x = 10\n",
    "        split_y = 10\n",
    "        if self.hist_bins is None:\n",
    "            #self.hist_bins = [1, 282.10434686113894, 528.4350826042349, 635.7632261805744, 781.9301580581496, 962.0317275933281, 1079.2939329789033, 1246.3707282050862, 1393.0345691835053, 1721.8292294917992]\n",
    "            self.hist_bins = [  1.00000000e+00,   2.43148939e+02 ,  5.52670768e+02,   6.63323565e+02,\n",
    "   7.82650357e+02 ,  1.02133853e+03 ,  1.08620935e+03,   1.20392913e+03,\n",
    "   1.39695300e+03 ,  1.75176484e+03]\n",
    "    \n",
    "        first = True\n",
    "        for row in X:\n",
    "            # use only without \"RemoveEmptyValues\"\n",
    "            # This is feature selection actually\n",
    "            if self.images_x_from is not False and self.images_x_to is not False:\n",
    "                #images = np.split(row, 176)[50:130] # pretty optimal already\n",
    "                images = np.split(row, 176)[self.images_x_from : self.images_x_to]\n",
    "                \n",
    "                # x needs to be set for this, but don't mind at the moment\n",
    "                if self.images_y_from is not False and self.images_y_to is not False:\n",
    "                    images_new = []\n",
    "                    for image in images:\n",
    "                        images_new.append(np.split(image, 208)[self.images_y_from : self.images_y_to])\n",
    "                    images = np.array(images_new)\n",
    "\n",
    "                row = np.array(images).flatten()\n",
    "                #features = []\n",
    "                #for image in images:\n",
    "                #    for split in np.array_split(image, 104):  \n",
    "                #        features.append(np.histogram(split, bins=hist_bins, density=False)[0])\n",
    "\n",
    "            splits = np.array_split(row, int(len(row) / self.splits))\n",
    "            features = []\n",
    "            for split in splits:\n",
    "                features.append(np.histogram(split, bins=self.hist_bins)[0])\n",
    "\n",
    "            X_new.append(np.array(features).flatten())\n",
    "            if first:\n",
    "                #print(\"features: \" + str(len(X_new[0])))\n",
    "                first = False\n",
    "\n",
    "        return X_new\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LinearRegression,BayesianRidge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('BinsExtraction', RandomBinsExtraction(splits=610,\n",
    "        bin_length=50, images_x_from=50, images_x_to=125, images_y_to=196)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('vct', VarianceThreshold(threshold=0.1)),\n",
    "    #('linreg', LinearRegression(n_jobs=-1))\n",
    "    #('bayes', BayesianRidge())\n",
    "    ('linearSVR', LinearSVR(C=1.0, max_iter=2000))\n",
    "    #('bagging', BaggingRegressor(LinearSVR(C=1.0, max_iter=2000), max_features=0.8, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.8179707593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ensemble import RandomEnsemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#pipe = RandomEnsemble()\n",
    "pipe.fit(X[0:150], y[0:150])\n",
    "print('fitted')\n",
    "y_pr = pipe.predict(X[151:228])\n",
    "print(mean_squared_error(y[151:228], y_pr))\n",
    "\n",
    "# 52.5900323473 var0.05 bins=10\n",
    "# 51.6259478991 better bins 41k\n",
    "# 51.3320775803 added 1-edges, 47k, /500\n",
    "# 51.6 /300, 78k\n",
    "# 52.2 /220, 106k\n",
    "# 55.5 /64, 366k\n",
    "# 51.1 linearsvr, /500, 53k\n",
    "# 51.6 /510\n",
    "# 51.5 /490\n",
    "# 49.56 /1000, random bins\n",
    "# 49.09 /610\n",
    "# 49.08 C=15\n",
    "# 49.0 max_iter=2000\n",
    "# 48.99 variance threshold=0.2\n",
    "# 47.39 better random bins again\n",
    "# 47.17 y_to=204\n",
    "# 46.938 x_to=132, (C=1, threshold=0.1)\n",
    "# 46.936 linreg\n",
    "# 46.82 x_to=125, y_to=196\n",
    "\n",
    "# 47.18 bagging\n",
    "# 47.86 RandomEnsemble\n",
    "# 90.9 /250\n",
    "# 51.7 /1000\n",
    "# 52.0 add random edge, 58k\n",
    "# 51.7 remove last edge, 47k\n",
    "# 52.1 /125, 187k\n",
    "# 52.8160909792 more better bins 99k\n",
    "# 67.7           kernelridge\n",
    "# 51.5455457395 much more bins 94k\n",
    "# 51.5211591462 less bins 31k\n",
    "# 51.6344647532 more bins 67k\n",
    "# 56            more better bins 87k features\n",
    "# 55.5 other splits2, 41k\n",
    "# 52.6655238717 other splits, 28k features\n",
    "# 56.237862326  14k features\n",
    "# 52.1237605257  56k features\n",
    "\n",
    "import os\n",
    "os.system('say \"i have finished!\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid.cv_results_\n",
    "#grid.best_params_\n",
    "#pipe.named_steps['vct'].variances_\n",
    "#len(pipe.named_steps['vct'].get_support(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n edges: 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([  316.06548606,   516.04062473,   672.03912953,   788.4017923 ,\n",
       "          912.68082233,  1063.06793716,  1221.11834124,  1370.37759073]),\n",
       " array([  308.77309614,   504.8323311 ,   661.04570736,   783.16988715,\n",
       "          921.22162422,  1080.41577968,  1247.41710179,  1393.10546197]),\n",
       " array([  259.42693236,   454.41115039,   637.10735577,   783.24697727,\n",
       "          918.05688785,  1076.03364154,  1238.7439229 ,  1383.01276065]),\n",
       " array([  284.2603614 ,   461.84852282,   647.97452156,   826.76038816,\n",
       "          980.3224361 ,  1135.55237028,  1308.37312973,  1473.53302531]),\n",
       " array([  277.75613471,   482.81300987,   649.12127803,   776.62490065,\n",
       "          913.78209436,  1076.42318956,  1235.8621241 ,  1375.33653253])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search bin subdivision so that there is highest variance\n",
    "# 1. Divide hist into bins over some rows\n",
    "# 2. Compute std -> divide bins where it's high, join/drop those where it's low\n",
    "# 3. Repeat / change rows\n",
    "kmeans = KMeans(n_clusters=8, n_jobs=-1, random_state=42)\n",
    "\n",
    "samples = X[0: 5]\n",
    "centers = []\n",
    "for i, sample in enumerate(samples):\n",
    "    # sample = sample[1672390 : -786303]\n",
    "\n",
    "    sample = sample[(sample > 0) & (sample < 1800)]\n",
    "    kmeans.fit(np.array([sample]).T)\n",
    "    centers.append(np.sort(np.array(kmeans.cluster_centers_).flatten()))\n",
    "\n",
    "    #samples[i] = sample\n",
    "    #print(str(i) + ' done')\n",
    "\n",
    "if True: # use all centers\n",
    "    values = np.array(centers).flatten()\n",
    "    values = np.sort(values)\n",
    "else: # take means of centers\n",
    "    values = np.mean(centers, axis=0)\n",
    "\n",
    "edges = [1] # leave out 0\n",
    "for center_1, center_2 in zip(values[:-1], values[1:]):\n",
    "    edges.append(.5 * (center_1 + center_2))\n",
    "\n",
    "print('n edges: ' + str(len(edges)))\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "edges = [1,\n",
    " 175,\n",
    " 190.0,\n",
    " 200,\n",
    " 210,\n",
    " 220,\n",
    " 230.0,\n",
    " 240,\n",
    " 250.29576676838963,\n",
    " 260.59153353677925,\n",
    " 270.7998907955566,\n",
    " 281.00824805433393,\n",
    " 296.51672876785585,\n",
    " 312.4192910985714,\n",
    " 328.7096455492857,\n",
    " 345, 365.11915911105507, 385.23831822211014, 421.68407741265736, 458.1298366032046, 517.3519134270805, 576.5739902509565, 609.5574644576008, 626.0492015609229, 642.540938664245, 655.0834926946815, 666.5424184427528, 680,\n",
    " 688.7915018861073, 697.5830037722146, 705.1660075444291, 712.7490113166436, 720.3320150888583, 730.1660075444291, 740, 747.7243484748634, 755.4486969497268, 763.1730454245902, 770.8973938994536,\n",
    " 778.3608893423097, 785.8243847851659, 792.7855130483395, 799.7466413115131, 807.5810902304434, 816.5985296073651, 825.6159689842868, 836.8877682054391, 848.1595674265914, 863.9400863362044, 879.7206052458175, 905.8611747488183, 932.0017442518191, 950.2522817644435, 968.5028192770679,\n",
    " 995.0990029527295, 1021.6951866283912, 1045.622987987501, 1084.7830302704533, 1123.9430725534057, 1178.3353557602009, 1203.4127942147347, 1228.4902326692686,\n",
    " 1240.8414534419671, 1253.1926742146657, 1265.5438949873642, 1277.8951157600625, 1288.9475578800311, 1300, 1309.8438400564696, 1319.6876801129395,\n",
    " 1329.5315201694093, 1339.375360225879, 1347.7457855765365, 1356.1162109271943, 1365.7868972366239, 1375.4575835460535, 1386.4285308142548, 1400,\n",
    " 1408.3298109092373, 1416.6596218184745, 1424.9894327277118, 1433.319243636949, 1442, 1448.5, 1461.25, 1470.625, 1480, 1490.0, 1500,1509.375,\n",
    " 1518.75,\n",
    " 1530,\n",
    " 1546.25,\n",
    " 1562.5,\n",
    " 1581.25,\n",
    " 1610,\n",
    " 1700.0]\n",
    "hists = []\n",
    "for x in X:#resample(X, n_samples=100):\n",
    "    hists.append(np.histogram(x, bins=edges)[0])\n",
    "    \n",
    "std_all = np.std(np.array(hists).flatten())\n",
    "for bin_i in range(len(hists[0])):\n",
    "    arr = [h[bin_i] for h in hists]\n",
    "    print(\"bin \"+str(bin_i)+\": \"+str(np.std(arr) / std_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "new_edges = edges # attention: 49 bins = 50 edges\n",
    "for i in range(1):\n",
    "    # compute hists for samples\n",
    "    hists = []\n",
    "    for x in X:\n",
    "        hists.append(np.histogram(x, bins=new_edges)[0])\n",
    "\n",
    "    ed = [1]\n",
    "    for bin_i in range(len(hists[0])):\n",
    "        # compute std for bin i\n",
    "        arr = [h[bin_i] for h in hists]\n",
    "        std = np.std(arr) / std_all\n",
    "        \n",
    "        if std > 0.35: # if std over threshold, split bin\n",
    "            ed.append(0.5 * (new_edges[bin_i] + new_edges[bin_i+1])) \n",
    "            \n",
    "        if std < 0.2: # if std too low, join with next bin\n",
    "            continue\n",
    "            \n",
    "        ed.append(new_edges[bin_i+1])\n",
    "        \n",
    "    new_edges = ed\n",
    "    if len(new_edges)>=120: break\n",
    "        \n",
    "print(len(new_edges))\n",
    "display(new_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def run(a, b):\n",
    "    \"\"\" class BinsExtraction(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, splits=610, hist_bins=None,\n",
    "            images_x_from=50, images_x_to=132,\n",
    "            images_y_from=0, images_y_to=204):\n",
    "            self.splits = splits\n",
    "            self.hist_bins = hist_bins\n",
    "\n",
    "            self.images_x_from = images_x_from\n",
    "            self.images_x_to = images_x_to\n",
    "            self.images_y_from = images_y_from\n",
    "            self.images_y_to = images_y_to\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def transform(self, X, y=None):\n",
    "            X_new = []\n",
    "            split_x = 10\n",
    "            split_y = 10\n",
    "            if self.hist_bins is None:\n",
    "                #self.hist_bins = [1, 282.10434686113894, 528.4350826042349, 635.7632261805744, 781.9301580581496, 962.0317275933281, 1079.2939329789033, 1246.3707282050862, 1393.0345691835053, 1721.8292294917992]\n",
    "                self.hist_bins = [  1.00000000e+00,   2.43148939e+02 ,  5.52670768e+02,   6.63323565e+02,\n",
    "   7.82650357e+02 ,  1.02133853e+03 ,  1.08620935e+03,   1.20392913e+03,\n",
    "   1.39695300e+03 ,  1.75176484e+03]\n",
    "\n",
    "            first = True\n",
    "            for row in X:\n",
    "                # use only without \"RemoveEmptyValues\"\n",
    "                # This is feature selection actually\n",
    "                if self.images_x_from is not False and self.images_x_to is not False:\n",
    "                    #images = np.split(row, 176)[50:130] # pretty optimal already\n",
    "                    images = np.split(row, 176)[self.images_x_from : self.images_x_to]\n",
    "\n",
    "                    # x needs to be set for this, but don't mind at the moment\n",
    "                    if self.images_y_from is not False and self.images_y_to is not False:\n",
    "                        images_new = []\n",
    "                        for image in images:\n",
    "                            images_new.append(np.split(image, 208)[self.images_y_from : self.images_y_to])\n",
    "                        images = np.array(images_new)\n",
    "\n",
    "                    row = np.array(images).flatten()\n",
    "                 \n",
    "                splits = np.array_split(row, int(len(row) / self.splits))\n",
    "                features = []\n",
    "                for split in splits:\n",
    "                    features.append(np.histogram(split, bins=self.hist_bins)[0])\n",
    "\n",
    "                X_new.append(np.array(features).flatten())\n",
    "                if first:\n",
    "                    first = False\n",
    "\n",
    "            return X_new\"\"\"\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('BinsExtraction', RandomBinsExtraction(splits=610,\n",
    "            bin_length=50, images_x_from=50, images_x_to=a, images_y_to=b)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('vct', VarianceThreshold(threshold=0.1)),\n",
    "        #('linreg', LinearRegression(n_jobs=-1))\n",
    "        #('bayes', BayesianRidge())\n",
    "        ('linearSVR', LinearSVR(C=1.0, max_iter=2000))\n",
    "        #('bagging', BaggingRegressor(LinearSVR(C=1.0, max_iter=2000), max_features=0.8, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X[0:150], y[0:150])\n",
    "    y_pr = pipe.predict(X[151:228])\n",
    "    print(\"%s\\t%s\\t%s\" % (mean_squared_error(y[151:228], y_pr), a, b))\n",
    "    #print(\"\\t\", hist_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.8094371778\t125\t185\n",
      "46.8002649838\t125\t186\n",
      "46.8155858249\t125\t187\n",
      "46.802685956\t125\t188\n",
      "46.8147920257\t125\t189\n",
      "46.8050398104\t125\t190\n",
      "46.8225787889\t125\t191\n",
      "46.8117644543\t125\t192\n",
      "46.8004643673\t125\t193\n",
      "46.8030598433\t125\t194\n",
      "46.809295247\t125\t195\n",
      "46.8001341505\t125\t196\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-38f5574f5eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#    run(i, 204)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m185\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-7e13fc15f08c>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     65\u001b[0m     ])\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0my_pr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m151\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m228\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\\t%s\\t%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m151\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m228\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             epsilon=self.epsilon, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    891\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "some_bins = [1, 282.10434686113894, 528.4350826042349, 635.7632261805744, 781.9301580581496, 962.0317275933281, 1079.2939329789033, 1246.3707282050862, 1393.0345691835053, 1721.8292294917992]\n",
    "#for i in range(300, 2000, 10):\n",
    "#    run(i, some_bins)\n",
    "#for i in range(0, 0):\n",
    "#    new_bins = [1]\n",
    "#    for j in range(1, len(some_bins)):\n",
    "#        b = some_bins[j]\n",
    "#        new_bins.append(random.uniform(b - 80, b + 80))\n",
    "#    run(610, np.sort(new_bins))   \n",
    "#for i in range(0, 30):\n",
    "#    run(0, 208-i)\n",
    "\n",
    "#for i in range(120, 133):\n",
    "#    run(i, 204)\n",
    "for i in range(185, 200):\n",
    "    run(125, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
