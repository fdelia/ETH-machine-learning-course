{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "X = np.load('data/X_train.npy')#[0:load_n]\n",
    "y = np.genfromtxt('data/y_1.csv', delimiter='\\n')#[0:load_n]\n",
    "#data_test = np.load('data/X_test.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import random\n",
    "random.seed(99)\n",
    "\n",
    "class GivenBinHistExtraction(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_new = []\n",
    "        X_new = X\n",
    "        return X_new\n",
    "\n",
    "class ClusteredHistExtraction(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=10, n_samples=3, images_x_from=False, images_x_to=False):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_samples = n_samples\n",
    "        self.images_x_from = images_x_from\n",
    "        self.images_x_to = images_x_to\n",
    "\n",
    "\n",
    "    def cutImage(self, x):\n",
    "        if self.images_x_from is not False and self.images_x_to is not False:\n",
    "            #images = np.split(row, 176)[50:130] # pretty optimal already\n",
    "            side_images = np.split(x, 176)[self.images_x_from : self.images_x_to]\n",
    "            x = np.array(side_images).flatten()\n",
    "        return x\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        samples = random.sample(list(X), self.n_samples)\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, n_jobs=-1, random_state=42)\n",
    "        # self.kmeans = MiniBatchKMeans(n_clusters=self.n_clusters, batch_size=100, random_state=42)\n",
    "\n",
    "        centers = []\n",
    "        for i, sample in enumerate(samples):\n",
    "            # sample = sample[1672390 : -786303]\n",
    "            sample = self.cutImage(sample)\n",
    "\n",
    "            sample = sample[(sample > 0) & (sample < 1800)]\n",
    "            self.kmeans.fit(np.array([sample]).T)\n",
    "            centers.append(np.sort(np.array(self.kmeans.cluster_centers_).flatten()))\n",
    "            \n",
    "            samples[i] = sample\n",
    "            #print(str(i) + ' done')\n",
    "\n",
    "        if True: # use all centers\n",
    "            values = np.array(centers).flatten()\n",
    "            values = np.sort(values)\n",
    "        else: # take means of centers\n",
    "            values = np.mean(centers, axis=0)\n",
    "\n",
    "        # compute cluster centers\n",
    "        #self.kmeans.fit(np.array(samples).T)\n",
    "        #values = self.kmeans.cluster_centers_.T\n",
    "        #print('fitted')\n",
    "\n",
    "        # mean of the clusters over the rows\n",
    "        #for i, v in enumerate(values.T):\n",
    "        #    values.T[i] = np.sort(v)\n",
    "\n",
    "        #values = np.mean(values.T, axis=0)\n",
    "\n",
    "        self.edges = [1] # leave out 0\n",
    "        for center_1, center_2 in zip(values[:-1], values[1:]):\n",
    "            self.edges.append(.5 * (center_1 + center_2))\n",
    "\n",
    "        print('n edges: ' + str(len(self.edges)))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # np.histogram to make bins from edges, counts the number of pixels\n",
    "        X_new = []\n",
    "        for x in X:\n",
    "            x = self.cutImage(x)\n",
    "            x = x[(x > 0) & (x < 1800)]\n",
    "            hist = np.histogram(x, bins=self.edges)\n",
    "            X_new.append(hist[0])\n",
    "\n",
    "        return X_new\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ClusteredHistExtraction', ClusteredHistExtraction(\n",
    "        n_clusters=8,n_samples=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('vct', VarianceThreshold()),\n",
    "    ('kernelRidge', KernelRidge(kernel='polynomial'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "0 done\n",
      "0 done\n",
      "0 done\n",
      "1 done\n",
      "1 done\n",
      "1 done\n",
      "1 done\n",
      "2 done\n",
      "n edges: 24\n",
      "2 done\n",
      "n edges: 24\n",
      "2 done\n",
      "n edges: 24\n",
      "2 done\n",
      "3 done\n",
      "n edges: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "0 done\n",
      "0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 done\n",
      "1 done\n",
      "1 done\n",
      "2 done\n",
      "0 done\n",
      "2 done\n",
      "3 done\n",
      "n edges: 32\n",
      "2 done\n",
      "n edges: 30\n",
      "3 done\n",
      "n edges: 32\n",
      "1 done\n",
      "2 done\n",
      "n edges: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "0 done\n",
      "0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 done\n",
      "1 done\n",
      "1 done\n",
      "0 done\n",
      "2 done\n",
      "2 done\n",
      "n edges: 30\n",
      "2 done\n",
      "1 done\n",
      "3 done\n",
      "n edges: 40\n",
      "3 done\n",
      "n edges: 40\n",
      "2 done\n",
      "3 done\n",
      "n edges: 40\n",
      "0 done\n",
      "1 done\n",
      "2 done\n",
      "n edges: 24\n",
      "-68.5395679288, 6.39975328753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    " #   'ClusteredHistExtraction__n_clusters': [8, 10],\n",
    " #   'ClusteredHistExtraction__n_samples': [3, 4]\n",
    "}\n",
    "grid = GridSearchCV(pipe, parameters, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "print(str(np.mean(grid.cv_results_['mean_test_score'])) + ', ' + str(np.mean(grid.cv_results_['std_test_score'])))\n",
    "\n",
    "# -68.8529277579, 5.72349220142\n",
    "# -68.5395679288, 6.39975328753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ClusteredHistExtraction__n_clusters': 8,\n",
       " 'ClusteredHistExtraction__n_samples': 3}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_\n",
    "#grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n edges: 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 268.59153353677925,\n",
       " 281.00824805433393,\n",
       " 296.51672876785585,\n",
       " 312.41929109857142,\n",
       " 385.23831822211014,\n",
       " 458.12983660320458,\n",
       " 472.33076634277745,\n",
       " 493.82267048266544,\n",
       " 510.43647791541645,\n",
       " 576.57399025095651,\n",
       " 642.540938664245,\n",
       " 648.54789979548752,\n",
       " 655.08349269468147,\n",
       " 666.54241844275282,\n",
       " 724.33201508885827,\n",
       " 779.89739389945362,\n",
       " 783.20843221048995,\n",
       " 785.82438478516588,\n",
       " 807.58109023044335,\n",
       " 869.72060524581752,\n",
       " 913.23145834367801,\n",
       " 915.91949110352323,\n",
       " 919.63925603546056,\n",
       " 950.7720301599602,\n",
       " 1021.6951866283912,\n",
       " 1069.5507893466106,\n",
       " 1076.2284155454829,\n",
       " 1078.4194846165499,\n",
       " 1107.9840749772698,\n",
       " 1178.3353557602009,\n",
       " 1228.4902326692686,\n",
       " 1237.3030234970834,\n",
       " 1243.0805123468485,\n",
       " 1277.8951157600625,\n",
       " 1339.3753602258789,\n",
       " 1372.8570616285097,\n",
       " 1379.1746465921135,\n",
       " 1388.0591113102987,\n",
       " 1433.3192436369491]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search bin subdivision so that there is highest variance\n",
    "# 1. Divide hist into bins over some rows\n",
    "# 2. Compute std -> divide bins where it's high, join/drop those where it's low\n",
    "# 3. Repeat / change rows\n",
    "kmeans = KMeans(n_clusters=8, n_jobs=-1, random_state=42)\n",
    "\n",
    "samples = X[0: 5]\n",
    "centers = []\n",
    "for i, sample in enumerate(samples):\n",
    "    # sample = sample[1672390 : -786303]\n",
    "\n",
    "    sample = sample[(sample > 0) & (sample < 1800)]\n",
    "    kmeans.fit(np.array([sample]).T)\n",
    "    centers.append(np.sort(np.array(kmeans.cluster_centers_).flatten()))\n",
    "\n",
    "    #samples[i] = sample\n",
    "    #print(str(i) + ' done')\n",
    "\n",
    "if True: # use all centers\n",
    "    values = np.array(centers).flatten()\n",
    "    values = np.sort(values)\n",
    "else: # take means of centers\n",
    "    values = np.mean(centers, axis=0)\n",
    "\n",
    "edges = [1] # leave out 0\n",
    "for center_1, center_2 in zip(values[:-1], values[1:]):\n",
    "    edges.append(.5 * (center_1 + center_2))\n",
    "\n",
    "print('n edges: ' + str(len(edges)))\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all: 34046.9077187\n",
      "bin 0: 0.170929685079\n",
      "bin 1: 0.233108022412\n",
      "bin 2: 0.300298796641\n",
      "bin 3: 0.289250223006\n",
      "bin 4: 0.25208573564\n",
      "bin 5: 0.20247089561\n",
      "bin 6: 0.123111247256\n",
      "bin 7: 0.116177258484\n",
      "bin 8: 0.411662399168\n",
      "bin 9: 0.300059741059\n",
      "bin 10: 0.157116370559\n",
      "bin 11: 0.145437471901\n",
      "bin 12: 0.33353549762\n",
      "bin 13: 0.116866950661\n",
      "bin 14: 0.115520430882\n",
      "bin 15: 0.157285126334\n",
      "bin 16: 0.135071121543\n",
      "bin 17: 0.485369873268\n",
      "bin 18: 0.330288279396\n",
      "bin 19: 0.538604842123\n",
      "bin 20: 0.241691843442\n",
      "bin 21: 0.311650693639\n",
      "bin 22: 0.559776247518\n",
      "bin 23: 0.24226248993\n",
      "bin 24: 0.0323234921872\n",
      "bin 25: 0.168634770148\n",
      "bin 26: 0.369191347641\n",
      "bin 27: 0.200794673137\n",
      "bin 28: 0.381564595421\n",
      "bin 29: 0.280386300957\n",
      "bin 30: 0.415855894297\n",
      "bin 31: 0.784174664009\n",
      "bin 32: 0.41589606747\n",
      "bin 33: 0.316120408977\n",
      "bin 34: 0.460273526592\n",
      "bin 35: 0.322596081508\n",
      "bin 36: 0.383536846517\n",
      "bin 37: 0.473695183792\n",
      "bin 38: 0.345546761405\n",
      "bin 39: 0.255133618355\n",
      "bin 40: 0.100600850032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "edges = [1,\n",
    " 180,\n",
    " 200,\n",
    " 220,\n",
    " 240,\n",
    " 260.59153353677925,\n",
    " 281.00824805433393,\n",
    " 296.51672876785585,\n",
    " 312.41929109857142,\n",
    " 385.23831822211014,\n",
    " 458.12983660320458,\n",
    " 510.43647791541645,\n",
    " 576.57399025095651,\n",
    " 642.540938664245,\n",
    " 655.08349269468147,\n",
    " 666.54241844275282,\n",
    " 680,\n",
    " 690,\n",
    " 720.33201508885827,\n",
    " 740,     \n",
    " 770.89739389945362,\n",
    " 785.82438478516588,\n",
    " 807.58109023044335,\n",
    " 869.72060524581752,\n",
    " 913.23145834367801,\n",
    " 919.63925603546056,\n",
    " 950.7720301599602,\n",
    " 1021.6951866283912,\n",
    " 1069.5507893466106,\n",
    " 1178.3353557602009,\n",
    " 1228.4902326692686,\n",
    " 1277.8951157600625,\n",
    " 1339.3753602258789,\n",
    " 1372.8570616285097,\n",
    " 1400,\n",
    " 1433.3192436369491,\n",
    " 1455,\n",
    " 1480,\n",
    " 1515,\n",
    " 1550,\n",
    " 1600,\n",
    " 1800]\n",
    "hists = []\n",
    "for x in X[0:100]:#resample(X, n_samples=100):\n",
    "    hists.append(np.histogram(x, bins=edges)[0])\n",
    "    \n",
    "std_all = np.std(np.array(hists).flatten())\n",
    "print(\"all: \"+str(std_all)); stds = []\n",
    "for bin_i in range(len(hists[0])):\n",
    "    arr = [h[bin_i] for h in hists]\n",
    "    print(\"bin \"+str(bin_i)+\": \"+str(np.std(arr) / std_all))\n",
    "    stds.append(np.std(arr) / std_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
